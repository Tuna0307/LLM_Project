# ğŸ“ IRRA â€” Intelligent RAG Revision Assistant

An AI-powered study companion for university students, built with **Retrieval-Augmented Generation (RAG)** and **Google Gemini**.

**Group 12 | AAI3008 Large Language Models**

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ““ **Multi-Notebook** | Organise study materials into separate isolated notebooks |
| ğŸ“š **Study Chat** | Ask questions grounded in your lecture materials with source citations |
| ğŸ’¬ **Chat History** | Browse, resume, and delete past study conversations |
| ğŸ“ **Exam Mode** | Practice with AI-generated MCQ, True/False, and Short Answer questions |
| ğŸ“¤ **Upload Notes** | Upload PDF, Word, PowerPoint, TXT, or Markdown lecture materials |
| ğŸ”§ **Settings** | Human-in-the-Loop (HITL) question validation and system management |
| ğŸ¤– **Agent Routing** | Automatically routes queries to RAG, direct LLM, or web search |
| ğŸ”„ **Self-Reflection** | Plan â†’ Act â†’ Observe â†’ Reflect â†’ Revise loop for answer quality |
| ğŸ§  **Conversation Memory** | Remembers past discussions across sessions with SQLite |
| ğŸ” **Hybrid Retrieval** | Dense embeddings + BM25 keyword search with cross-encoder reranking |
| ğŸ“Š **Multi-Hop Reasoning** | Decomposes complex queries into sub-queries for better synthesis |

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    React Frontend (Vite)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚Study Chat â”‚ Exam Mode â”‚Upload Notes  â”‚    Settings    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â”‚           â”‚            â”‚               â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚        â–¼           â–¼            â–¼               â–¼            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚                 FastAPI Backend                  â”‚      â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚      â”‚
â”‚   â”‚  â”‚  Agent  â”‚ â”‚Quiz Modeâ”‚ â”‚  Ingest  â”‚  â”‚Settingsâ”‚ â”‚      â”‚
â”‚   â”‚  â”‚ Router  â”‚ â”‚(Student)â”‚ â”‚ Pipeline â”‚  â”‚ HITL  â”‚ â”‚      â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚           â”‚                       â”‚                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                   â”‚
â”‚   â”‚         Hybrid Retriever            â”‚                   â”‚
â”‚   â”‚  Dense (ChromaDB) + Sparse (BM25)   â”‚                   â”‚
â”‚   â”‚      + Cross-Encoder Reranker       â”‚                   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                   â”‚                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚   â”‚       Google Gemini API             â”‚                   â”‚
â”‚   â”‚  LLM: gemini-2.5-flash              â”‚                   â”‚
â”‚   â”‚  Embeddings: gemini-embedding-001   â”‚                   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚   â”‚         Storage Layer               â”‚                   â”‚
â”‚   â”‚  ChromaDB â”‚ SQLite (Memory+Quiz)    â”‚                   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.10+**
- **Node.js 18+**
- **Google Gemini API key** (free tier) â€” get one at [Google AI Studio](https://aistudio.google.com/apikey)

### 1. Clone & install dependencies

```bash
git clone <repo-url>
cd LLM_Project

# Install Python backend dependencies
pip install -r requirements.txt

# Install Node.js frontend dependencies
cd frontend
npm install
cd ..
```

### 2. Set up your API key

```bash
# Copy the example env file
copy .env.example .env
```

Edit `.env` and add your Google Gemini API key:

```
GOOGLE_API_KEY=your-google-api-key-here
```

### 3. Run the application

You will need two terminal windows to run the backend and frontend separately.

**Terminal 1: Start the FastAPI Backend**
```bash
# From the root directory (activate your Python environment first)
python -m uvicorn api:app --host 0.0.0.0 --port 8001
```
The API will be available at **http://localhost:8001**.

**Terminal 2: Start the React Frontend**
```bash
# From the frontend directory
cd frontend
npm run dev
```
The app will open at **http://localhost:5173**.

### 4. Upload course materials

Navigate to **ğŸ“¤ Upload Notes** and drag-and-drop your lecture materials (PDF, DOCX, PPTX, TXT, or Markdown).

### 5. Start studying!

- Use **ğŸ“š Study Chat** to ask questions about your materials â€” your conversations are saved and resumable
- Use **ğŸ“ Exam Mode** to test yourself with AI-generated questions
- Use **ğŸ”§ Settings** to review/edit AI-generated questions (HITL)

---

## ğŸ“ Project Structure

```
LLM_Project/
â”œâ”€â”€ api.py                  # FastAPI entry point (all REST endpoints)
â”œâ”€â”€ config.py               # Central configuration (API keys, model settings)
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .env                    # API keys (NOT tracked in git â€” copy from .env.example)
â”œâ”€â”€ .env.example            # Template for .env
â”‚
â”œâ”€â”€ src/                    # Core backend modules
â”‚   â”œâ”€â”€ __init__.py         # Package init with public API exports
â”‚   â”œâ”€â”€ ingest.py           # File ETL pipeline (PDF, DOCX, PPTX, TXT â†’ chunks)
â”‚   â”œâ”€â”€ vectorstore.py      # ChromaDB vector store (embeddings, search, CRUD)
â”‚   â”œâ”€â”€ retriever.py        # Hybrid retrieval (Dense + BM25 + RRF + reranking)
â”‚   â”œâ”€â”€ agent.py            # Query router + self-reflection loop
â”‚   â”œâ”€â”€ memory.py           # Conversation memory (SQLite, per-notebook sessions)
â”‚   â”œâ”€â”€ quiz_mode.py        # Quiz generation + HITL validation pipeline
â”‚   â””â”€â”€ citations.py        # Source citation formatting
â”‚
â”œâ”€â”€ frontend/               # React + Vite frontend
â”‚   â”œâ”€â”€ package.json        # Node.js dependencies
â”‚   â”œâ”€â”€ vite.config.ts      # Vite build config (port 5173)
â”‚   â””â”€â”€ src/
â”‚       â””â”€â”€ app/
â”‚           â”œâ”€â”€ App.tsx     # Root component
â”‚           â”œâ”€â”€ routes.ts   # React Router routes
â”‚           â”œâ”€â”€ pages/      # Notebooks, Chat, Exam, Upload, Settings, Home
â”‚           â”œâ”€â”€ layouts/    # DashboardLayout (per-notebook sidebar)
â”‚           â”œâ”€â”€ context/    # NotebookContext (multi-notebook state)
â”‚           â””â”€â”€ components/ # shadcn/ui component library
â”‚
â”œâ”€â”€ prompts/                # LLM prompt templates
â”‚   â”œâ”€â”€ system_prompt.txt   # Main system persona
â”‚   â”œâ”€â”€ routing_prompt.txt  # Query classification
â”‚   â”œâ”€â”€ reflection_prompt.txt # Answer self-evaluation
â”‚   â””â”€â”€ quiz_prompt.txt     # Question generation
â”‚
â”œâ”€â”€ data/                   # Data directories (uploads not tracked in git)
â”‚   â””â”€â”€ raw/                # Uploaded files (PDF, DOCX, PPTX, TXT, MD)
â”‚
â””â”€â”€ db/                     # Persistent storage (auto-created on first run)
    â”œâ”€â”€ chroma/             # ChromaDB vector database
    â”œâ”€â”€ memory.db           # Conversation memory (SQLite)
    â””â”€â”€ quiz.db             # Question bank (SQLite)
```

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|-----------|
| **LLM** | Google Gemini 2.5 Flash (free tier) |
| **Embeddings** | Google Gemini Embedding 001 |
| **Framework** | LangChain 0.3+ |
| **Vector Store** | ChromaDB |
| **Sparse Search** | BM25 (rank-bm25) |
| **Reranker** | cross-encoder/ms-marco-MiniLM-L-6-v2 |
| **Frontend** | React 18 + Vite + shadcn/ui + Tailwind CSS |
| **Backend API** | FastAPI + Uvicorn |
| **Memory/Quiz DB** | SQLite |
| **PDF Processing** | PyPDF |

---

## âš™ï¸ Configuration

All settings are centralized in `config.py`:

| Setting | Default | Description |
|---------|---------|-------------|
| `LLM_MODEL` | `gemini-2.5-flash` | Google Gemini model for generation |
| `EMBEDDING_MODEL` | `models/gemini-embedding-001` | Embedding model |
| `CHUNK_SIZE` | `500` | Characters per text chunk |
| `CHUNK_OVERLAP` | `50` | Overlap between chunks |
| `TOP_K_RETRIEVAL` | `10` | Initial retrieval candidates |
| `TOP_K_RERANK` | `5` | Final results after reranking |
| `MAX_REFLECTION_ITERATIONS` | `2` | Max self-reflection loops |
| `CONFIDENCE_THRESHOLD` | `0.6` | Minimum answer confidence |

---

## ğŸ“ Professor's Advanced Suggestions Implemented

This project addresses the following advanced directions suggested by the course professor:

1. **Multi-Agent Routing** â€” Agent router classifies queries and dispatches to specialized handlers (RAG, direct, web search, quiz)
2. **Self-Reflection Loop** â€” Plan â†’ Act â†’ Observe â†’ Reflect â†’ Revise cycle evaluates answer quality and retries when confidence is low
3. **Human-in-the-Loop (HITL)** â€” Settings page enables teachers to review, edit, accept, or reject AI-generated quiz questions
4. **Hybrid Retrieval with Multi-Hop** â€” Combines dense and sparse retrieval with Reciprocal Rank Fusion, cross-encoder reranking, and multi-hop sub-query decomposition
5. **Long-Term Memory** â€” SQLite-backed conversation memory with periodic LLM-based summarization across sessions; full chat history browsable from the UI

---

## âš ï¸ Rate Limits

Google Gemini's **free tier** has the following limits:

| Resource | Limit |
|----------|-------|
| LLM requests | 15 requests/minute |
| Embedding requests | 100 requests/minute |

The upload pipeline includes **automatic rate limiting** (small batches with 15s delays) and **retry logic** for 429 errors.

---

## ğŸ‘¥ Team â€” Group 12

| Member | Role | Primary Files |
|--------|------|---------------|
| Wei Xuan | Data Infrastructure | `ingest.py` |
| Jay | Storage & Embeddings | `vectorstore.py` |
| Shunren | Core RAG Logic | `retriever.py`, `agent.py` |
| Praveen | Frontend Interface | `frontend/src/` |
| Delvin | Feature Engineering | `quiz_mode.py`, `citations.py` |

---